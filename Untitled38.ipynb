{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONMSEJlbdm/JMylaBER3+8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fedor44/perceptron/blob/main/Untitled38.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jCCbfQFJ8aP",
        "outputId": "06514127-8f09-42cc-fcff-24390452dada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-16.0, -5.0] -0.1\n",
            "[-16.0, -5.0] -0.1\n",
            "[-16.0, -5.0] -0.1\n",
            "[1.0, 3.0] 0.0\n",
            "[1.0, 3.0] 0.0\n",
            "[1.0, 3.0] 0.0\n",
            "[-15.0, -2.0] -0.1\n",
            "[-15.0, -2.0] -0.1\n",
            "[-15.0, -2.0] -0.1\n",
            "[2.0, 6.0] 0.0\n",
            "[2.0, 6.0] 0.0\n",
            "[2.0, 6.0] 0.0\n",
            "[-14.0, 1.0] -0.1\n",
            "[-14.0, 1.0] -0.1\n",
            "[-14.0, 1.0] -0.1\n",
            "[3.0, 9.0] 0.0\n",
            "[3.0, 9.0] 0.0\n",
            "[3.0, 9.0] 0.0\n",
            "[-13.0, 4.0] -0.1\n",
            "[-13.0, 4.0] -0.1\n",
            "[-13.0, 4.0] -0.1\n",
            "[4.0, 12.0] 0.0\n",
            "[4.0, 12.0] 0.0\n",
            "[4.0, 12.0] 0.0\n",
            "[-12.0, 7.0] -0.1\n",
            "[-12.0, 7.0] -0.1\n",
            "[-12.0, 7.0] -0.1\n",
            "[5.0, 15.0] 0.0\n",
            "[5.0, 15.0] 0.0\n",
            "[5.0, 15.0] 0.0\n",
            "[-11.0, 10.0] -0.1\n",
            "[-11.0, 10.0] -0.1\n",
            "[-11.0, 10.0] -0.1\n",
            "[6.0, 18.0] 0.0\n",
            "[6.0, 18.0] 0.0\n",
            "[6.0, 18.0] 0.0\n",
            "[-10.0, 13.0] -0.1\n",
            "[-10.0, 13.0] -0.1\n",
            "[-10.0, 13.0] -0.1\n",
            "[7.0, 21.0] 0.0\n",
            "[7.0, 21.0] 0.0\n",
            "[7.0, 21.0] 0.0\n",
            "[-9.0, 16.0] -0.1\n",
            "[-9.0, 16.0] -0.1\n",
            "[-9.0, 16.0] -0.1\n",
            "[8.0, 24.0] 0.0\n",
            "[8.0, 24.0] 0.0\n",
            "[8.0, 24.0] 0.0\n",
            "[-8.0, 19.0] -0.1\n",
            "[-8.0, 19.0] -0.1\n",
            "[-8.0, 19.0] -0.1\n",
            "[-8.0, 19.0] -0.1\n",
            "[-8.0, 19.0] -0.1\n",
            "[10.0, 26.0] 0.0\n",
            "[-6.0, 21.0] -0.1\n",
            "[-6.0, 21.0] -0.1\n",
            "[-22.5, 16.2] -0.2\n",
            "[-5.5, 24.2] -0.1\n",
            "[-5.5, 24.2] -0.1\n",
            "[-5.5, 24.2] -0.1\n",
            "[-21.5, 19.2] -0.2\n",
            "[-21.5, 19.2] -0.2\n",
            "[-21.5, 19.2] -0.2\n",
            "[-4.5, 27.2] -0.1\n",
            "[-4.5, 27.2] -0.1\n",
            "[-4.5, 27.2] -0.1\n",
            "[-20.5, 22.2] -0.2\n",
            "[-20.5, 22.2] -0.2\n",
            "[-20.5, 22.2] -0.2\n",
            "[-3.5, 30.2] -0.1\n",
            "[-3.5, 30.2] -0.1\n",
            "[-3.5, 30.2] -0.1\n",
            "[-19.5, 25.2] -0.2\n",
            "[-19.5, 25.2] -0.2\n",
            "[-19.5, 25.2] -0.2\n",
            "[-2.5, 33.2] -0.1\n",
            "[-2.5, 33.2] -0.1\n",
            "[-2.5, 33.2] -0.1\n",
            "[-18.5, 28.200000000000003] -0.2\n",
            "[-18.5, 28.200000000000003] -0.2\n",
            "[-18.5, 28.200000000000003] -0.2\n",
            "[-1.5, 36.2] -0.1\n",
            "[-1.5, 36.2] -0.1\n",
            "[-1.5, 36.2] -0.1\n",
            "[-17.5, 31.200000000000003] -0.2\n",
            "[-17.5, 31.200000000000003] -0.2\n",
            "[-17.5, 31.200000000000003] -0.2\n",
            "[-0.5, 39.2] -0.1\n",
            "[-0.5, 39.2] -0.1\n",
            "[-0.5, 39.2] -0.1\n",
            "[-16.5, 34.2] -0.2\n",
            "[-16.5, 34.2] -0.2\n",
            "[-16.5, 34.2] -0.2\n",
            "[0.5, 42.2] -0.1\n",
            "[0.5, 42.2] -0.1\n",
            "[0.5, 42.2] -0.1\n",
            "[-15.5, 37.2] -0.2\n",
            "[-15.5, 37.2] -0.2\n",
            "[-15.5, 37.2] -0.2\n",
            "[-15.5, 37.2] -0.2\n",
            "[-15.5, 37.2] -0.2\n",
            "[2.5, 44.2] -0.1\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "[-13.5, 39.2] -0.2\n",
            "에포크 번호=18, 학습률=0.100, 오류=0.000\n",
            "==== 결과 ====\n",
            "[-13.5, 39.2] -0.2\n"
          ]
        }
      ],
      "source": [
        "def calculate(input):\n",
        "  global weights\n",
        "  global bias\n",
        "  activation = bias # 바이어스\n",
        "  for i in range(2): # 입력신호 총합 계산\n",
        "    activation += weights[i] * input[i]\n",
        "  \n",
        "  if activation >= 0.0: # 스텝 활성화 함수\n",
        "    return 1.0\n",
        "  else:\n",
        "    return 0.0\n",
        "\n",
        "\n",
        "def train_weights(X, y, l_rate, n_epoch):\n",
        "  global weights\n",
        "  global bias\n",
        "  \n",
        "  for epoch in range(n_epoch): # 에포크 반복\n",
        "    sum_error = 0.0\n",
        "    for row, target in zip(X, y): # 데이터셋을 반복\n",
        "      actual = calculate(row) # 실제 출력 계산\n",
        "      error = target - actual # 실제 출력 계산\n",
        "      bias = bias + l_rate * error\n",
        "      sum_error += error**2 # 오류의 제곱 계산\n",
        "\n",
        "      for i in range(2): # 가중치 변경\n",
        "        weights[i] = weights[i] + l_rate * error * row[i]\n",
        "\n",
        "      print(weights, bias)\n",
        "  \n",
        "  print('에포크 번호=%d, 학습률=%.3f, 오류=%.3f' % (epoch, l_rate, sum_error))\n",
        "  return weights\n",
        "\n",
        "\n",
        "# AND 연산 학습 데이터셋, 샘플과 레이블이다.\n",
        "X = [[160,50],[163,43],[165,48],[170,80],[175,76],[180,70]]\n",
        "y = [0, 0, 0, 1, 1, 1]\n",
        "# 가중치와 바이어스 초기값\n",
        "weights = [0.0, 0.0]\n",
        "bias = 0.0\n",
        "l_rate = 0.1 # 학습률\n",
        "n_epoch = 19 # 에포크 횟수\n",
        "weights = train_weights(X, y, l_rate, n_epoch)\n",
        "print(\"==== 결과 ====\")\n",
        "print(weights, bias)\n"
      ]
    }
  ]
}